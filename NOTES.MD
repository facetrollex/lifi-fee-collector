# Notes

## INPUT
### Summary

We have a Smart Contract which is responsible for collecting fees for our
transactions when certain conditions are met. This contract is called the
FeeCollector and its deployed to all EVM chains that we support.

Every time a transaction is submitted that includes fee collection, an event is emitted
here on this contract. You can see those events .

We would like to have the functionality to scan those emitted events, store them in
our database and request them based on the integrator that the fees were collected
for.

### Acceptance Criteria

- We would like to have a tool that scrapes the contract for emitted FeesCollected event on a given chain
- The tool should be able to be started at any time to retrieve new events
- The tool should work efficiently and not scan the same blocks again
- The retrieved events should be stored in a MongoDB database using Typegoose
- Optional 1: Write a small REST endpoint that allows to retrieve all collected events for a given integrator
- Optional 2: Wrap the application into a usable Docker image
- The solution should be built in TypeScript, it should include all information on how to run it

### Implementation Consideration

- You can focus on the Polygon Chain for now, but the concept should take into
consideration that we want this for all our EVM chains
- You can use 78600000 as the oldest block to take into consideration

----

## Output
### Functional Requirements

- tool that scrapes contract for emitted FeesCollected event on a given chain
- tool should be able to be started at any time to retrieve new events
- deduplication process: tool should not scan same block again
- retrieved events should be stored in MongoDB
- API tool that allows retrieval of all collected events for a given integrator.
- tool should be wrapped into a usable Docker image.

### Non Functional Requirements

- Efficiency: application should work efficiently, should not rescan same blocks again
- Operability: can be started any time
- Extensibility: application should accommodate all supported EVM chains (at some point)
- Assumption(!) - Scalability: Worker should be able to work via multiple instances (horizontal scaling)

### Constraints

- Implementation Language: TS
- Typegoose package for modeling
- MongoDB as data storage
- DataSource: Events come from deployed FeeCollector contracts emitted FeesCollected events
- Chain scope: Polygon
- Historical Start Point: 78600000 as the oldest block to consider

### AI Usage

- AI validation for FR/NFR
- Initial Prototype:
  - generate docker image (with MongoDB / node inside)
  - generate 2 entry points for 2 different apps (API + worker)
  - install node / ts / typegoose as these are constraints for our project.
- Mongo Schema validation
- Structure changes (file movements into dirs) -> all references updated + sanity check.
- RPC test connection method generated by AI (check if contract address is valid)
- Docker compose changes (split instances, multiple workers, production/development modes)
- Edge cases testing (aka lint process for logic from agent):
  - multiple instances -> single batch available (real-time scrape)
  - multiple instances -> error validation between steps, retry process
- integrator -> to chainId replacement process
- Unit Testing (manual validation for cases)
- Documentation

### Challenges / Blockers

- Deduplication process (multiple instances) with MongoDB -> leaseExpired functionality added (for Jobs)
- Batch size (for scraping): public polygon load balancer routes 'free tier' requests to various backend providers and some of them have extremely low or even broken eth_get_Logs limits. -> Reduced batch size (from 100 initially, to 10)

Note: in 'real' production rpc batch size can be much larger, 1000-5000

### Reasoning behind solution, decisions made

- Single Docker image with node / mongo as per requirements: Acceptance Criteria -> Optional 2 (docker image (not images)) -> UPD: changed this to 2 images as it is anti-pattern to do this under single image (also it giving a lot of complexity to manage such solution in production)
- Splitting API / Worker as 2 separate entrypoints, as we might need to scale worker based on 'needs' to scrape faster (in such case no reason to scale API)
- Successful scrapes is deleted from BlockJobs collection, no reason to store them as they already processed
- Divided scrapping process for 'stages' for smooth gathering process
- how to divide data based on integrator? Initially I just implemented an integrator prop (string 'polygon', with possibility to add other chains in future, like 'etherium' & etc) as identifier for jobs / lastblock tracking / events tracking / configuration, but later came to the idea that this is not a good approach and most likely it will be better to use chainID as identifier (common approach for blockchain). Ref: https://chainlist.org/?search=polygon

## Next steps you would take or any areas you didn't have time to implement fully

### RPC Provider Unavailable

Current state:
- we are using just single provider
- if the provider becomes unavailable -> we will just 'wait'.

Solution:

1.1 Use additional RPC:
- single fallback rpc (not resilient as both can be not available)
- pool of rpcs (preffered)

1.2 Introduce resiliency layer (RPCBalancer)
- This balancer will be used by all RPC calls and will check/gather stats (health) about them.

1.3 Fallback behaviour:
- on retryable RPC error, automatically route the same request to the next healthy provider.

1.4 Routing strategy:
- start with simple round-robin over healthy endpoints (can evolve to latency (as example) later).

### Chain Reorganization case

ref: https://mplankton.substack.com/p/polygons-block-reorg-problem

Currently:
- No check for such behaviour

Solution:
- Check 'past' scraped blocks and mark events as 'unrelated/deleted' if they are not actual anymore

### Historical vs Realtime scraping

Currently:
- historical: scrape with delay 20s
- realtime: scrape with delay 1m (to reduce numbers of RPC calls)

Solution (not ideal):
Treat state with adaptive scheduling:
- historical mode: run almost continuously while lag exists; don't sleep after successful work, only pause on errors/rate-limit pressure.
- realtime mode: prefer push-based head updates (WebSocket newBlock), and keep HTTP polling as fallback with short interval + jitter + exponential backoff when chain is quiet.
- Adaptive batch size: increase block range when responses are healthy, reduce on timeout/error
